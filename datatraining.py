# -*- coding: utf-8 -*-
"""datatraining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FbSn0mrooqBDFUvHPjqefhjbBisPAUjU
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import cv2
import os
from sklearn.utils import shuffle
import random
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Input, concatenate
from tensorflow.keras.applications import VGG16, ResNet50
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, Callback

class EarlyStoppingByValAcc(Callback):
    def __init__(self, patience=2):
        super(EarlyStoppingByValAcc, self).__init__()
        self.patience = patience
        self.best_val_acc = -np.Inf
        self.wait = 0

    def on_epoch_end(self, epoch, logs=None):
        current_val_acc = logs.get("val_accuracy")
        if np.isclose(current_val_acc, self.best_val_acc, atol=1e-5):
            self.wait += 1
            if self.wait >= self.patience:
                self.model.stop_training = True
                print(f"\nStopping training as validation accuracy did not improve for {self.patience} consecutive epochs.")
        else:
            self.best_val_acc = current_val_acc
            self.wait = 0

def show_images(path):
    labels = os.listdir(path)
    fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(15, 6))
    random_indices = random.sample(range(1, 101), 10)

    for i, idx in enumerate(random_indices, 1):
        file_path = os.path.join(path, labels[idx])
        image = Image.open(file_path)
        subplot_row = (i - 1) // 5
        subplot_col = (i - 1) % 5
        axes[subplot_row, subplot_col].imshow(image)
        axes[subplot_row, subplot_col].axis('off')
    plt.tight_layout()
    plt.show()

def read_data(path, image_size, classes):
    X = []
    y = []
    labels = os.listdir(path)
    for label in labels:
        try:
            for image in os.listdir(os.path.join(path, label)):
                img = cv2.imread(os.path.join(path, label, image))
                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
                img = cv2.resize(img, (image_size, image_size))
                # Convert grayscale to RGB
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
                X.append(img)
                y.append(classes[label])
        except:
            pass
    return np.array(X), np.array(y)

# Adjusted class labels to start from 0
knee2_classes = {'0Normal': 0, '1Doubtful': 1, '2Mild': 2, '3Moderate': 3, '4Severe': 4}

x_traindig_knee, y_traindig_knee = read_data('/content/drive/My Drive/t1', 200, knee2_classes)
x_testdig_knee, y_testdig_knee = read_data('/content/drive/My Drive/t2', 200, knee2_classes)

x_traindig_knee, y_traindig_knee = shuffle(x_traindig_knee, y_traindig_knee, random_state=42)
x_testdig_knee, y_testdig_knee = shuffle(x_testdig_knee, y_testdig_knee, random_state=42)

x_knee = np.concatenate((x_traindig_knee, x_testdig_knee))
y_knee = np.concatenate((y_traindig_knee, y_testdig_knee))

x_train, x_test, y_train, y_test = train_test_split(x_knee, y_knee, test_size=0.25, random_state=42)

print(x_train.shape)
print(x_test.shape)

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Load base models
base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))
base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))

# Extract features from both models
vgg16_output = base_model_vgg16.output
resnet50_output = base_model_resnet50.output

# Flatten features and concatenate
vgg16_flatten = Flatten()(vgg16_output)
resnet50_flatten = Flatten()(resnet50_output)
combined_features = concatenate([vgg16_flatten, resnet50_flatten])

# Add custom classifier layers
x = Dense(256, activation='relu')(combined_features)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(32, activation='relu')(x)
output = Dense(5, activation='softmax')(x)

# Combine base models and custom classifier into a single model
model = Model(inputs=[base_model_vgg16.input, base_model_resnet50.input], outputs=output)

# Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Define the filepath to save the model
model_checkpoint = ModelCheckpoint('/content/drive/My Drive/fyp/FYP2_best_val_acc.h5',
                                   monitor='val_accuracy',
                                   save_best_only=True,
                                   mode='max',
                                   verbose=1)

# Define EarlyStoppingByValAcc callback
early_stopping = EarlyStoppingByValAcc(patience=2)

# Train the model
history = model.fit(
    [x_train, x_train],
    y_train,
    epochs=150,
    batch_size=32,
    validation_data=([x_test, x_test], y_test),
    callbacks=[model_checkpoint, early_stopping]
)

# Plot training history
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Load the best model saved by ModelCheckpoint
best_model = load_model('/content/drive/My Drive/fyp/FYP2_best_val_acc.h5')

# Evaluate the best model
y_pred = best_model.predict([x_test, x_test])
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)
print(classification_report(y_true_classes, y_pred_classes))

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_true_classes, y_pred_classes), annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()